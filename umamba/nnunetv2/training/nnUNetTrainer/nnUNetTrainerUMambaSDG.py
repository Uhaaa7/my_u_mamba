import torch
from nnunetv2.training.nnUNetTrainer.nnUNetTrainerUMambaBot import nnUNetTrainerUMambaBot
from nnunetv2.utilities.plans_handling.plans_handler import ConfigurationManager, PlansManager
from torch import nn
from nnunetv2.nets.UMambaBot_2d import get_umamba_bot_2d_from_plans

class nnUNetTrainerUMambaSDG(nnUNetTrainerUMambaBot):
    """
    ã€åˆ›æ–°ç‚¹è®­ç»ƒå™¨ Oursã€‘
    ç»§æ‰¿è‡ªåŸç‰ˆ Trainerï¼Œä½†åœ¨æ„å»ºç½‘ç»œæ—¶å¼ºåˆ¶æ‰“å¼€ enable_sdg=Trueã€‚
    å¹¶ä¸”é‡å†™äº† train_step ä»¥åŠ å…¥æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢ NaNã€‚
    """

    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict, unpack_dataset: bool = True,
                 device: torch.device = torch.device('cuda')):
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(plans, configuration, fold, dataset_json, unpack_dataset, device)
        
        # ğŸ‘‡ğŸ‘‡ğŸ‘‡ ã€æ ¸å¿ƒä¿®æ”¹ã€‘é™ä½åˆå§‹å­¦ä¹ ç‡ ğŸ‘‡ğŸ‘‡ğŸ‘‡
        # é»˜è®¤æ˜¯ 1e-2 (0.01)ï¼Œå¯¹äº BS=4 + Mamba æ¥è¯´å¤ªæ¿€è¿›äº†
        # æ”¹ä¸º 1e-3 (0.001)ï¼Œç¨³æ‰ç¨³æ‰“
        self.initial_lr = 1e-3
        self.num_epochs = 500
        print("ğŸ”¥ğŸ”¥ğŸ”¥ æˆåŠŸåŠ è½½äº†æˆ‘çš„ä¿®æ”¹ç‰ˆ Trainerï¼åˆå§‹ LR = 1e-3 ğŸ”¥ğŸ”¥ğŸ”¥")
    @staticmethod
    def build_network_architecture(plans_manager: PlansManager,
                                   dataset_json,
                                   configuration_manager: ConfigurationManager,
                                   num_input_channels,
                                   enable_deep_supervision: bool = True) -> nn.Module:

        if len(configuration_manager.patch_size) == 2:
            model = get_umamba_bot_2d_from_plans(
                plans_manager, 
                dataset_json, 
                configuration_manager,
                num_input_channels, 
                deep_supervision=enable_deep_supervision,
                enable_sdg=True  # <--- âœ… æ˜¾å¼å¼€å¯ SDG æ¨¡å— (è·‘æ”¹è¿›ç‰ˆ)
            )
        
        elif len(configuration_manager.patch_size) == 3:
             raise NotImplementedError("SDG-Block 3D version not implemented yet")
        else:
            raise NotImplementedError("Only 2D models are supported for SDG-Block currently")
        
        print("ğŸš€ğŸš€ğŸš€ [Ours Mode] UMambaBot with SDG-Block ENABLED! ğŸš€ğŸš€ğŸš€")

        return model

    # ğŸ‘‡ğŸ‘‡ğŸ‘‡ æŠŠè¿™ä¸ªå‡½æ•°åŠ åœ¨è¿™é‡Œï¼è¿™å°±åŠ ä¸Šäº†æ¢¯åº¦è£å‰ª ğŸ‘‡ğŸ‘‡ğŸ‘‡
    def train_step(self, batch: dict) -> dict:
        data = batch['data']
        target = batch['target']

        data = data.to(self.device, non_blocking=True)
        if isinstance(target, list):
            target = [i.to(self.device, non_blocking=True) for i in target]
        else:
            target = target.to(self.device, non_blocking=True)

        self.optimizer.zero_grad(set_to_none=True)

        # Autocast æ˜¯ nnU-Net é»˜è®¤å¼€å¯çš„
        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=True):
            output = self.network(data)
            l = self.loss(output, target)

        if self.grad_scaler is not None:
            self.grad_scaler.scale(l).backward()
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šåœ¨ scaler.step ä¹‹å‰è§£åŒ…å¹¶è£å‰ªæ¢¯åº¦ ğŸ”¥ğŸ”¥ğŸ”¥
            # è¿™å°±æ˜¯é˜²æ­¢ NaN çš„ç»å¯¹é˜²å¾¡
            self.grad_scaler.unscale_(self.optimizer)
            torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12.0)
            
            self.grad_scaler.step(self.optimizer)
            self.grad_scaler.update()
        else:
            l.backward()
            # å¦‚æœæ²¡ç”¨ scaler (æå°‘è§)ï¼Œä¹ŸåŠ ä¸Šè£å‰ª
            torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12.0)
            self.optimizer.step()

        return {'loss': l.detach().cpu().numpy()}